{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1bd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc29a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting & bagging\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fa15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting & Stacking\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980f35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fae8b",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd76638",
   "metadata": {},
   "source": [
    "## les différentes combinaisons possibles de LR + RF + GBC + XGB en vote hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e4e5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sources/df_final_rolling_ready_50_with_bookodds.csv')\n",
    "    \n",
    "# Encodage\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.concat([df['player_1_name'], df['player_2_name']], axis=0))\n",
    "df['player_1_name_encoded'] = le.transform(df['player_1_name'])\n",
    "df['player_2_name_encoded'] = le.transform(df['player_2_name'])\n",
    "\n",
    "# Suppression player_1_name & player_2\n",
    "df.drop(['player_1_name', 'player_2_name'], axis=1, inplace=True)\n",
    "\n",
    "# Dichotomisation\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Split\n",
    "nb_rows_train = int(round(len(df)*0.7,0))\n",
    "X_train = df.drop('player_1_win', axis=1)[:nb_rows_train]\n",
    "y_train = df['player_1_win'][:nb_rows_train]\n",
    "X_test = df.drop('player_1_win', axis=1)[nb_rows_train:]\n",
    "y_test = df['player_1_win'][nb_rows_train:]\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modèles\n",
    "clf_lr = LogisticRegression(C=0.005, max_iter=2000, penalty='l1', random_state=42, solver='liblinear')\n",
    "clf_rf = RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=75, random_state=10)\n",
    "clf_gbc = GradientBoostingClassifier(learning_rate=0.1,max_depth=1, n_estimators=60, random_state=0)\n",
    "clf_xgb = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bynode=1, \n",
    "                            colsample_bytree=1, learning_rate=0.1, max_depth=2, min_child_weight=15, \n",
    "                            n_estimators=50, n_jobs=-1, random_state=0, subsample=1, tree_method='exact')\n",
    "\n",
    "vclf = {}\n",
    "\n",
    "vclf_1 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf), ('gbc', clf_gbc), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_1.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_1.named_estimators_.keys())] = vclf_1.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_2 = VotingClassifier(estimators=[('rf', clf_rf), ('gbc', clf_gbc), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_2.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_2.named_estimators_.keys())] = vclf_2.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_3 = VotingClassifier(estimators=[('lr', clf_lr), ('gbc', clf_gbc), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_3.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_3.named_estimators_.keys())] = vclf_3.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_4 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_4.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_4.named_estimators_.keys())] = vclf_4.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_5 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf), ('gbc', clf_gbc)], voting='hard')\n",
    "vclf_5.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_5.named_estimators_.keys())] = vclf_5.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_6 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf)], voting='hard')\n",
    "vclf_6.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_6.named_estimators_.keys())] = vclf_6.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_7 = VotingClassifier(estimators=[('lr', clf_lr), ('gbc', clf_gbc)], voting='hard')\n",
    "vclf_7.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_7.named_estimators_.keys())] = vclf_7.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_8 = VotingClassifier(estimators=[('lr', clf_lr), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_8.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_8.named_estimators_.keys())] = vclf_8.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_9 = VotingClassifier(estimators=[('rf', clf_rf), ('gbc', clf_gbc)], voting='hard')\n",
    "vclf_9.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_9.named_estimators_.keys())] = vclf_9.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_10 = VotingClassifier(estimators=[('rf', clf_rf), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_10.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_10.named_estimators_.keys())] = vclf_10.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_11 = VotingClassifier(estimators=[('gbc', clf_gbc), ('xgb', clf_xgb)], voting='hard')\n",
    "vclf_11.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_11.named_estimators_.keys())] = vclf_11.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e901a592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"dict_keys(['lr', 'rf', 'gbc', 'xgb'])\": 0.6744186046511628,\n",
       " \"dict_keys(['rf', 'gbc', 'xgb'])\": 0.673953488372093,\n",
       " \"dict_keys(['lr', 'gbc', 'xgb'])\": 0.6753488372093023,\n",
       " \"dict_keys(['lr', 'rf', 'xgb'])\": 0.6747674418604651,\n",
       " \"dict_keys(['lr', 'rf', 'gbc'])\": 0.6740697674418604,\n",
       " \"dict_keys(['lr', 'rf'])\": 0.6753488372093023,\n",
       " \"dict_keys(['lr', 'gbc'])\": 0.6758139534883721,\n",
       " \"dict_keys(['lr', 'xgb'])\": 0.674186046511628,\n",
       " \"dict_keys(['rf', 'gbc'])\": 0.6733720930232558,\n",
       " \"dict_keys(['rf', 'xgb'])\": 0.6731395348837209,\n",
       " \"dict_keys(['gbc', 'xgb'])\": 0.6734883720930233}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27c8fab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758139534883721"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclf_7.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0dd331cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2nd_Best_VC_LR_RF.joblib']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(vclf_7, 'Best_VC_LR_GBC.joblib')\n",
    "dump(vclf_6, '2nd_Best_VC_LR_RF.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9890acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758139534883721"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load('Best_VC_LR_GBC.joblib')\n",
    "loaded_model.predict(X_test_scaled)\n",
    "loaded_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4a51e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753488372093023"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load('2nd_Best_VC_LR_RF.joblib')\n",
    "loaded_model.predict(X_test_scaled)\n",
    "loaded_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da801a",
   "metadata": {},
   "source": [
    "## les différentes combinaisons possibles de LR + RF + GBC + XGB en vote soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bb3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sources/df_final_rolling_ready_50_with_bookodds.csv')\n",
    "    \n",
    "# Encodage\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.concat([df['player_1_name'], df['player_2_name']], axis=0))\n",
    "df['player_1_name_encoded'] = le.transform(df['player_1_name'])\n",
    "df['player_2_name_encoded'] = le.transform(df['player_2_name'])\n",
    "\n",
    "# Suppression player_1_name & player_2\n",
    "df.drop(['player_1_name', 'player_2_name'], axis=1, inplace=True)\n",
    "\n",
    "# Dichotomisation\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Split\n",
    "nb_rows_train = int(round(len(df)*0.7,0))\n",
    "X_train = df.drop('player_1_win', axis=1)[:nb_rows_train]\n",
    "y_train = df['player_1_win'][:nb_rows_train]\n",
    "X_test = df.drop('player_1_win', axis=1)[nb_rows_train:]\n",
    "y_test = df['player_1_win'][nb_rows_train:]\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modèles\n",
    "clf_lr = LogisticRegression(C=0.005, max_iter=2000, penalty='l1', random_state=42, solver='liblinear')\n",
    "clf_rf = RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=75, random_state=10)\n",
    "clf_gbc = GradientBoostingClassifier(learning_rate=0.1,max_depth=1, n_estimators=60, random_state=0)\n",
    "clf_xgb = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bynode=1, \n",
    "                            colsample_bytree=1, learning_rate=0.1, max_depth=2, min_child_weight=15, \n",
    "                            n_estimators=50, n_jobs=-1, random_state=0, subsample=1, tree_method='exact')\n",
    "\n",
    "vclf = {}\n",
    "\n",
    "vclf_1 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf), ('gbc', clf_gbc), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_1.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_1.named_estimators_.keys())] = vclf_1.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_2 = VotingClassifier(estimators=[('rf', clf_rf), ('gbc', clf_gbc), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_2.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_2.named_estimators_.keys())] = vclf_2.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_3 = VotingClassifier(estimators=[('lr', clf_lr), ('gbc', clf_gbc), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_3.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_3.named_estimators_.keys())] = vclf_3.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_4 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_4.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_4.named_estimators_.keys())] = vclf_4.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_5 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf), ('gbc', clf_gbc)], voting='soft')\n",
    "vclf_5.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_5.named_estimators_.keys())] = vclf_5.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_6 = VotingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf)], voting='soft')\n",
    "vclf_6.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_6.named_estimators_.keys())] = vclf_6.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_7 = VotingClassifier(estimators=[('lr', clf_lr), ('gbc', clf_gbc)], voting='soft')\n",
    "vclf_7.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_7.named_estimators_.keys())] = vclf_7.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_8 = VotingClassifier(estimators=[('lr', clf_lr), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_8.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_8.named_estimators_.keys())] = vclf_8.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_9 = VotingClassifier(estimators=[('rf', clf_rf), ('gbc', clf_gbc)], voting='soft')\n",
    "vclf_9.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_9.named_estimators_.keys())] = vclf_9.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_10 = VotingClassifier(estimators=[('rf', clf_rf), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_10.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_10.named_estimators_.keys())] = vclf_10.score(X_test_scaled, y_test)\n",
    "\n",
    "vclf_11 = VotingClassifier(estimators=[('gbc', clf_gbc), ('xgb', clf_xgb)], voting='soft')\n",
    "vclf_11.fit(X_train_scaled, y_train)\n",
    "vclf[str(vclf_11.named_estimators_.keys())] = vclf_11.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cca38dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"dict_keys(['lr', 'rf', 'gbc', 'xgb'])\": 0.6743023255813954,\n",
       " \"dict_keys(['rf', 'gbc', 'xgb'])\": 0.6727906976744186,\n",
       " \"dict_keys(['lr', 'gbc', 'xgb'])\": 0.6744186046511628,\n",
       " \"dict_keys(['lr', 'rf', 'xgb'])\": 0.6747674418604651,\n",
       " \"dict_keys(['lr', 'rf', 'gbc'])\": 0.6743023255813954,\n",
       " \"dict_keys(['lr', 'rf'])\": 0.6738372093023256,\n",
       " \"dict_keys(['lr', 'gbc'])\": 0.6748837209302325,\n",
       " \"dict_keys(['lr', 'xgb'])\": 0.6748837209302325,\n",
       " \"dict_keys(['rf', 'gbc'])\": 0.6722093023255814,\n",
       " \"dict_keys(['rf', 'xgb'])\": 0.6722093023255814,\n",
       " \"dict_keys(['gbc', 'xgb'])\": 0.674186046511628}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cab82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2nd_Best_VC_LR_RF_XGB.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(vclf_7, 'Best_VC_LR_GBC.joblib')\n",
    "dump(vclf_4, '2nd_Best_VC_LR_RF_XGB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e22a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748837209302325"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load('Best_VC_LR_GBC.joblib')\n",
    "loaded_model.predict(X_test_scaled)\n",
    "loaded_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dccdfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6747674418604651"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load('2nd_Best_VC_LR_RF_XGB.joblib')\n",
    "loaded_model.predict(X_test_scaled)\n",
    "loaded_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e42ab",
   "metadata": {},
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0aba55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6738372093023256"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Sources/df_final_rolling_ready_50_with_bookodds.csv')\n",
    "    \n",
    "# Encodage\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.concat([df['player_1_name'], df['player_2_name']], axis=0))\n",
    "df['player_1_name_encoded'] = le.transform(df['player_1_name'])\n",
    "df['player_2_name_encoded'] = le.transform(df['player_2_name'])\n",
    "\n",
    "# Suppression player_1_name & player_2\n",
    "df.drop(['player_1_name', 'player_2_name'], axis=1, inplace=True)\n",
    "\n",
    "# Dichotomisation\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Split\n",
    "nb_rows_train = int(round(len(df)*0.7,0))\n",
    "X_train = df.drop('player_1_win', axis=1)[:nb_rows_train]\n",
    "y_train = df['player_1_win'][:nb_rows_train]\n",
    "X_test = df.drop('player_1_win', axis=1)[nb_rows_train:]\n",
    "y_test = df['player_1_win'][nb_rows_train:]\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modèles\n",
    "clf_lr = LogisticRegression(C=0.005, max_iter=2000, penalty='l1', random_state=42, solver='liblinear')\n",
    "clf_rf = RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=75, random_state=10)\n",
    "clf_gbc = GradientBoostingClassifier(learning_rate=0.1,max_depth=1, n_estimators=60, random_state=0)\n",
    "clf_xgb = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bynode=1, \n",
    "                            colsample_bytree=1, learning_rate=0.1, max_depth=2, min_child_weight=15, \n",
    "                            n_estimators=50, n_jobs=-1, random_state=0, subsample=1, tree_method='exact')\n",
    "\n",
    "sclf_1 = StackingClassifier(estimators=[('lr', clf_lr), ('rf', clf_rf)], final_estimator=clf_lr)\n",
    "sclf_1.fit(X_train_scaled, y_train)\n",
    "sclf_1.score(X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
